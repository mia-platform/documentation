---
id: data_catalog_job_runner
title: Job Runner
sidebar_label: Job Runner
---

import runnerSchema from "@site/static/schemas/data_fabric/data-catalog-job-runner.config.schema.json"
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Data Catalog _Job Runner_ can trigger the execution of different jobs that can update the state of the Data Catalog solution. 

The service keeps an internal queue where different requests sent by the Data Catalog UI are processed and executed, while collecting feedback
that can be sent back to clients that need to obtain information about the status of the current jobs that are running.

## Available Jobs

Here are listed the main jobs that the service can execute. 

### Data Catalog Agent

_Data Catalog Agent_ is a routine that, given a __Connection__, queries datasources for the data schemas of the resources they own and stores them into the Data Catalog storage layer
as documents compliant to the [Open Lineage specification](https://openlineage.io/). It provides facilities to:

1. query tables schemas;
2. aggregate them in a unique JSON format;
3. store the resulting datasets into the MongoDb database of the Data Catalog application

#### Odbc Connections

In the context of databases, it requires [Open Database Connectivity (ODBC)](https://en.wikipedia.org/wiki/Open_Database_Connectivity) drivers to connect to external DBMS.
The service comes already equipped with the following ODBC drivers:

- ODBC Driver 18 for SQL Server,
- MySQL ODBC 9.1 Unicode Driver,
- MySQL ODBC 9.1 ANSI Driver,
- MySQL ODBC 8.0 Unicode Driver,
- MySQL ODBC 8.0 ANSI Driver,
- PostgreSQL ANSI,
- PostgreSQL Unicode,
- Oracle 23 ODBC driver,
- Saphana HDBODBC

### Data Catalog Sync

_Data Catalog Sync_ is a routine that is automatically scheduled after a _Data Catalog Agent job_: its duty is to align the datasets retrieved previously by the Agent
and convert theminto assets that can be managed by the Data Catalog application.

## Configuration

### Environment Variables

Fabric BFF can be customized using the following environment variables:

| Name                          | Required | Description                                                                                                                       | Default Value                       |
|-------------------------------|----------|-----------------------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| `GRPC_PORT`                   | -        | This variable determines the TCP port where the **GRPC controller** binds its listener                                            | 50051                               |
| `LOG_LEVEL`                   | -        | Specify the centralized application log level, choosing from options such as `debug`, `error`, `info`, `trace` or `warn`          | `info`                              |
| `JOB_RUNNER_FOLDER`           | -        | Set the location of the configuration files                                                                                       | `~/job-runner`                      |
| `ODBCINI`                     | -        | Optional full path where a custom `.odbc.ini` can be used to retrieve user defined data sources                                   | `~/job-runner/.odbc.ini`            |

### Main Configuration

The [main configuration](#main-configuration) of the service is handled by a `config.json`, located at the path defined by the `JOB_RUNNER_FOLDER`.

When instantiating [Data Catalog application](/runtime_suite_applications/data-catalog/10_overview.md), Job Runner service configuration is generated with
a dedicated Config Map, named `job-runner-config`. This file contains a template configuration that should help in configuring the service.

<SchemaViewer schema={runnerSchema}/>

In the paragraph below is explained how to configure the persistence layer.

#### Persistence Layer

:::info
Currently only [MongoDB](https://mongodb.com/) is supported as persistence layer for storing relevant data.
:::

:::caution
The MongoDB database selected for storing Data Catalog data **must be configured to have [`replicaSet` enabled](https://www.mongodb.com/docs/manual/replication/)**, since
Job Runner exploits features that can be used only when a `replicaSet` is available.
:::

In order to carry out all its operations, Job Runner requires a _persistence layer_ where relevant information, such as auditing details, are stored. This configuration can be set under
the `persistence.configuration` key of the configuration file. The main properties are:

- `url` &rarr; the connection string to your MongoDB instance;
- `database` &rarr; the database name where to search for the  collections relevant to Job Runner service. Please notice that setting this property will **override** the database
name potentially set in the connection string;

An example of persistence configuration can be seen below:

```json
{
  "persistence": {
    "type": "mongodb",
    "configuration": {
      "url": "mongodb://<server>:27017/<default-database>?replicaSet=local",
      "database": "<data-fabric-database-name>"
    }
  }
}
```

:::tip
The following properties support [secret resolution](/fast_data/configuration/secrets_resolution.md):
- `persistence.configuration.url`
- `persistence.configuration.database`
:::

### Secrets Names Configuration

To let the Data Catalog UI be aware of possible secret that can be used within connection definitions, the service can be additionaly 
configured with a `secret.json` file located at the `JOB_RUNNER_FOLDER`.

The corresponding JSON is a key-value pair representation where:

- the keys represent the __secret name__ that can be used by external services as reference when triggering a job;
- the values repesent a secret (that can be either represent according to [Fast Data secret resolution](/fast_data/configuration/secrets_resolution.md))

<details>
<summary>Example Configuration</summary>

Consider the following sample `secrets.json`:

```json
{
  "secretPlain": "{{MY_PLAIN_SECRET}}",
  "secretEnv": {
    "type": "env",
    "key": "EXAMPLE_ENV"
  },
  "secretFile": {
    "type": "file",
    "path": "/run/secrets/job_runner/example.ini",
    "key": "EXAMPLE_ENV"
  }
}
```

The [gRPC method `ListSecretNames`](#configuration-1) will return the following response:

```json
["secretPlain", "secretEnv", "secretFile"]
```

</details>

:::caution
When the service receives a request to trigger a job, it will first try to reselove the secrets contained in the request by looking at the entries of this file: 
if no secret can be found, the service will try to read the corresponding secret from the process environment. 
:::

### ODBC Configuration

An ODBC connection can configured either by the means of Connection String or Data Source Name (DSN).

Connection String is a string of key-value pairs where each of them represents a parameter of your connection.

Data Source Name (DSN) are symbolic names that can be linked to an ODBC connection. Job Runner service can read into a user-defined `.odbc.ini` file to load
at runtime the ODBC connections that can be executed through DSN. The list of available DSN then can be used by the Data Catalog UI while configuring an ODBC connection.

Job Runner reads DSN in its user-defined `.odbc.ini` located by default in the main configuration folder. To learn more about DSN and their connection parameters, 
please refer [to the official documentation](https://learn.microsoft.com/en-us/sql/connect/odbc/dsn-connection-string-attribute).

Here are listed some example for the supported ODBC drivers:

#### Oracle

Job Runner needs additional configuration to run jobs towards Oracle databases. 

With Oracle databases, connectivity can be handled with [`tnsnames.ora` files and/or wallets](https://docs.oracle.com/en/database/oracle/oracle-database/18/netrf/local-naming-parameters-in-tnsnames-ora-file.html#GUID-12C94B15-2CE1-4B98-9D0C-8226A9DDF4CB).

#### Tsnames

The service expects such assets in the Config Map located at `/opt/oracle/instantclient/network/admin/`, which must be checked to not owerwrite the content of the whole folder. 

#### Wallets

Oracle Wallet contains authentication and signal credentials of a database, which needs to be built with the whole service. 

To add an oracle wallet to Job Runner service, you have to __replace the microservice container with a custom container located in your registry.
This custom container consists of a `Dockerfile`, which uses the Job Runner service as base layer and adds on top of it the desired wallets.

Once the custom wallets are copied into the container's `/opt/oracle/instantclient/network/admin/`, you can tune the `sqlora.net` file registering the path `/opt/oracle/instantclient/network/admin/`. 
This path can be overridden by the means of the environment variable `TNS_ADMIN`. 

```docker title=Dockerfile
FROM nexus.mia-platform.eu/data-fabric/job-runner:<latest version>
COPY <wallet location> /opt/oracle/instantclient/network/admin/

COPY <<EOF /opt/oracle/instantclient/network/admin/sqlora.net
WALLET_LOCATION = (SOURCE = (METHOD = file) (METHOD_DATA = (DIRECTORY="/opt/oracle/instantclient/network/admin"))) SSL_SERVER_DN_MATCH=yes

EOF
```

<Tabs groupId='oracle-odbc' queryString>

<TabItem value="connection-string" label="Connection String">

The list of all the available connection parameters can be found in the [official Oracle documentation](https://docs.oracle.com/en//database/oracle/oracle-database/23/odbcd/basic-programming-oracle-odbc.html#GUID-634470F3-DAEE-481D-9EB4-16BF1FC6ABA2).

```
driver=Oracle 23 ODBC driver;dbq=<SERVERNAME>;uid=<UID>;pwd=<PWD>;
```

Please note that `dbq` field can either be the an entry of your `tsnames.ora` file or an inline entry such as:

```
(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.0.0.0)(PORT=5041))(CONN ...))
```

</TabItem>

<TabItem value="dsn" label="DSN">

Here's an example of a `.odbc.ini` file containing an Oracle DSN.

```ini
# 👇 change the placeholder with the name of your connection
[{CONNECTION NAME}]
AggregateSQLType=FLOAT
Application Attributes=T
Attributes=W
BatchAutocommitMode=IfAllSuccessful
BindAsFLOAT=F
CacheBufferSize=20
CloseCursor=F
# 👇 ...optional description
Description= 
DisableDPM=F
DisableMTS=T
DisableRULEHint=T
Driver=Oracle 23 ODBC driver
EXECSchemaOpt=
EXECSyntax=T
Failover=T
FailoverDelay=10
FailoverRetryCount=10
FetchBufferSize=64000
ForceWCHAR=F
LobPrefetchSize=8192
Lobs=T
Longs=T
MaxLargeData=0
MaxTokenSize=8192
MetadataIdDefault=F
# 👇 ...db password credentials
Password= 
QueryTimeout=T
ResultSets=T
# 👇 ...here goes the DBQ field of the connection string, or an entry name of a configured tsnames.ora
ServerName= 
SQLGetData extensions=F
SQLTranslateErrors=F
StatementCache=F
Translation Option=0
UseOCIDescribeAny=F
# 👇 ...db username credentials
UserID= 
```

</TabItem>

</Tabs>

#### PostgreSQL

<Tabs groupId='pgsql-odbc' queryString>

<TabItem value="connection-string" label="Connection String">

The list of all the available connection parameters can be found in the [official documentation](https://odbc.postgresql.org/docs/config-opt.html).

```
driver={PostgreSQL Unicode};server=<HOSTNAME>;port=5432;uid=<UID>;pwd=<PWD>;database=<DATABASE>;
```

</TabItem>
<TabItem value="dsn" label="DSN">

Here's an example of a `.odbc.ini` file containing a PostgreSQL DSN.

```ini
; 👇 change the placeholder with your connection name
[{NAME}]
; 👇 here goes the name of the database you want to connect
Database= 
; 👇 [optional] here goes the description of your connection
Description=
Driver=PostgreSQL Unicode
Port=5432
; 👇 database host location
ServerName= 
; 👇 database username
Username=
; 👇 database password
Password=
```

</TabItem>
</Tabs>

#### MySQL

<Tabs groupId='mysql-odbc' queryString>

<TabItem value="connection-string" label="Connection String">

The list of all the available connection parameters can be found in the [official documentation](https://dev.mysql.com/doc/connector-odbc/en/connector-odbc-configuration-connection-without-dsn.html).

```
driver={MySQL ODBC 9.1 Unicode Driver};server=<HOSTNAME>;port=5432;uid=<UID>;pwd=<PWD>;database=<DATABASE>;
```

</TabItem>
<TabItem value="dsn" label="DSN">

Here's an example of a `.odbc.ini` file containing a MySQL DSN. (for more details, refer to the [official documentation](https://dev.mysql.com/doc/connector-odbc/en/connector-odbc-configuration-dsn-unix.html))

```ini
; 👇 change the placeholder with your connection name
[{NAME}]
Driver=MySQL ODBC 9.1 Unicode Driver
; 👇 here goes the port of your database (if not specified, defaults to 3306)
Port=
; 👇 here goes the name of the database you want to connect
Database=
; 👇 database host location
Server= 
; 👇 database username
Username=
; 👇 database password
Password=
```

</TabItem>
</Tabs>

#### MSSQL

You can refer to [the official documentation](https://learn.microsoft.com/en-us/sql/connect/odbc/dsn-connection-string-attribute?view=sql-server-ver16) for a list of all the supported parameters.

<Tabs groupId='mssql-odbc' queryString>

<TabItem value="connection-string" label="Connection String">

```
Driver={ODBC Driver 18 for SQL Server};Server=<HOSTNAME>;Database=<DBNAME>;Uid=<USERNAME>;Pwd=<PWD>;TrustServerCertificate=yes
```

</TabItem>
<TabItem value="dsn" label="DSN">

Here's an example of a `.odbc.ini` file containing a MSSQL DSN. Username and password must be provided from the Data Catalog UI.

```ini
; 👇 change the placeholder with your connection name
[{NAME}]
Driver=ODBC Driver 18 for SQL Server
; 👇 here goes the name of the database you want to connect
Database=
; 👇 write in the form of "tcp:<hostname>,<port number>"
Server=
; 👇 enable self-signed encryption
TrustServerCertificate=yes
```

</TabItem>
</Tabs>

#### Saphana

<Tabs groupId='saphana-odbc' queryString>

<TabItem value="connection-string" label="Connection String">

You can refer to [the official documentation](https://help.sap.com/docs/SAP_HANA_CLIENT/f1b440ded6144a54ada97ff95dac7adf/7cab593774474f2f8db335710b2f5c50.html) for a list of all the supported parameters.

```
Driver={Saphana HDBODBC};ServerNode=<HOSTNAME>:<PORT>;DatabaseName=<DBNAME>;UID=<USERNAME>;PWD=<PWD>;
```

</TabItem>
<TabItem value="dsn" label="DSN">

Here's an example of a `.odbc.ini` file containing a Saphana DSN. Username and password must be provided from the Data Catalog UI.

```ini
; 👇 change the placeholder with your connection name
[{NAME}]
Driver=Saphana HDBODBC
; 👇 here goes the name of the database you want to connect
DatabaseName=
; 👇 write in the form of "<hostname>:<port number>"
ServerNode=
```

</TabItem>
</Tabs>

## gRPC Services

The request exchanged between Fabric BFF and Job Runner services are performed through [gRPC](https://grpc.io/).

Thus, on Job Runner service is necessary to advertise the port where the gRPC controller is exposed, which by default is the `50051`.
This operation can be achieved by setting the proper port to the list of [_Container Ports_](/development_suite/api-console/api-design/microservice-container-ports.md)
that can be found in the Console Design area, under the specific microservice resource.

:::tip
When instantiating Data Catalog application, _Container Ports_ are pre-filled with all the needed ports using their default value.  
In case the gRPC port chosen through [environment variables](#environment-variables) has been edited, please change the _Container Ports_ accordingly.
:::

Here are listed the main services that are exposed by the service.

### ODBC Client

Service responsible to retrieve information about the status of the ODBC driver. It has the following methods:
  - `ListDrivers`: unary RPC returning the list of drivers configured within the service;
  - `ListDataSources`: unary RPC returning the list of data sources configured within the service.
### Configuration

Service responsible to retrieve information about the main configuration of the service. It has the following methods:
  - `ListSecretNames`: unary RPC returning the names of secrets configured in the [Secret Names Configuration section](#secret-names-configuration).
### Job Runner 

Service responsible to interact with the JobRunner service. It has the following methods:
  - `Run`: unary RPC that receive the context of a job and executes it, returning the corresponding identifier;
  - `List`: unary RPC returning the list of jobs that have been executed by the service;
  - `Status`: server streaming RPC returning feedback messages from the active jobs.  

